On Understanding User Choices: Textual Correlates of Relevance Judgements
   An empirical investigation of the role of documents in relevance judgements
is reported.. Abstracts previously judged relevant, partially relevant, and 
nonrelevant to each of 61 questions were compared to see whether textual 
differences could be found which might reasonably account for the rating 
differences.. The results of this comparison were fairly clear-cut 
characterizations in each case of relevant and partially relevant abstracts.. 
These characterizations were found to be expressible largely as meaningful
co-occurrences of terms closely related to the question.. It is suggested that 
the textual bases of user choices may be more understandable than has been 
supposed..
